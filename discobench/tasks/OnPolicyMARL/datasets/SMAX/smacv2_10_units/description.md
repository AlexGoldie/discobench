DESCRIPTION
SMAX is a purely JAX-based SMAC (StarCraft Multi-Agent Challenge)-like environment for decentralised unit micromanagement. Two teams of units engage on a 32×32 map: one team of ally agents (learned policies) and one team of enemies (built-in heuristic). Each agent step advances the environment by 8 internal physics steps, each 1/16 of a second, giving smooth unit movement and combat resolution. Units can move, stop, or attack enemies within range. The objective is to eliminate all enemy units before losing the entire allied team.

MULTI AGENT ENVIRONMENT
One agent is assigned to each allied unit. Agents act simultaneously and observe only their own local egocentric view; observations are not shared between agents. Enemy units are controlled by the HeuristicEnemySMAX policy, which attacks the closest ally. Because each agent acts from partial information, coordination must emerge entirely from the learned joint policy.

OBSERVATION SPACE
The observation type is unit_list. Each agent receives a flat vector of shape (257,) built from three groups of features:

Own unit (10 features): normalised health (health / max_health), normalised x/y position (pos / map_size), weapon cooldown, unit type as a 6-bit one-hot vector
Each other allied unit (13 features each, 9 entries): normalised health, relative x/y position normalised by the observing unit's sight range, previous movement vector (x, y), previous attack target index, weapon cooldown, unit type one-hot
Each enemy unit (13 features each, 10 entries): same 13-feature structure; previous actions are visible because see_enemy_actions=True

Units outside the observing unit's sight range appear with all-zero features. All values are continuous real numbers.
Total observation size: 13×(10−1) + 13×10 + 10 = 257

ACTION SPACE
Each agent selects one discrete action per step:

0–3: move in four directions
4: stop (also used as no-op by dead units)
5–14: attack enemy unit 0 through 9

Total actions per ally agent: 15 (5 movement/stop + 10 attack targets). Unavailable actions (e.g. attacking a unit out of range, moving when dead) are masked each step (GET_AVAIL_ACTIONS=True).

TRANSITION DYNAMICS
Each agent step runs 8 internal world steps. In each world step, all units act simultaneously: each unit either moves in its chosen direction at its type-specific velocity (scaled by time_per_step = 1/16 s) or attacks a target. A unit can move or attack but not both in the same world step. An attack succeeds if the target is within attack range and the attacker's weapon cooldown is ≤ 0; the cooldown is then reset to the unit's type-specific value plus a small random deviation. All damage is accumulated and applied simultaneously across the world step. Overlapping units are pushed apart after each world step. A unit touching the map boundary (≤ 0 or ≥ 32) dies immediately (walls_cause_death=True). Dead units are removed and their agent is forced to issue stop.

REWARD
All allied agents share the same team reward computed each step:

Dense reward: sum of normalised enemy health decreases this step, divided by the number of enemy units (proportional to damage dealt)
Win bonus: +1.0 when all enemy units are eliminated and at least one ally survives

There is no explicit loss penalty. Dead agents still receive the team reward to allow for sacrificial play.

STARTING STATE
Starting positions are generated by the SurroundAndReflect distribution each episode rather than fixed locations, so initial unit placement varies between episodes. Unit types are also randomised each episode (smacv2_unit_type_generation=True), drawn from the full set: marine (health 45, range 5.0), marauder (health 125, range 6.0), stalker (health 160, range 6.0), zealot (health 150, range 2.0, melee), zergling (health 35, range 2.0, melee), hydralisk (health 80, range 5.0). All units start with full health and zero weapon cooldown.

EPISODE END
Win: all enemy units are eliminated and at least one ally is alive
Loss: all allied units are eliminated
Truncation: episode length reaches max_steps = 100 agent steps

SCENARIO
10 randomly chosen allied units vs 10 randomly chosen enemy units. A medium-scale SMACv2 scenario with randomised unit types and starting positions each episode. The policy must generalise across all possible 10-unit compositions drawn from the 6 unit types, while also coordinating 10 simultaneous agents from partial observations. At this scale, both the generalisation challenge (adapting to mixed teams of ranged and melee units) and the coordination challenge (focus-fire across 10 agents) are significantly harder than in smacv2_5_units. The 6-bit unit type one-hot in each agent's observation is the key signal for inferring appropriate combat behaviour. Total allied agents: 10. Observation size: 257. Actions per agent: 15.
