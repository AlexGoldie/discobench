Bayesian Optimisation (BO) is a branch of machine learning that aims to find the maximum of an expensive black-box function whose gradient is unknown. It does so by constructing a surrogate model (a probabilistic approximation of the objective function) that quantifies both predicted performance and uncertainty. Using this model, BO selects new evaluation points through an acquisition function that balances exploration of uncertain regions with exploitation of promising areas.

The process begins with an initial set of samples, often chosen to cover the search space effectively using methods such as Latin hypercube or Sobol sampling. These samples are used to fit the surrogate model, typically via maximum likelihood estimation or Bayesian inference over model parameters. The surrogate is then iteratively updated as new data become available.

In the past, Gaussian Processes (GPs) have been the most common choice of Surrogate Model, offering a flexible non-parametric prior over functions. Variants employ different kernels (e.g., Matérn, RBF, periodic), or combinations of kernels, and mean functions to capture diverse function classes. Extensions handle heteroscedastic noise or non-stationarity. For higher-dimensional or data-rich settings, scalable alternatives such as random forests (SMAC), Bayesian neural networks, and deep kernel learning have been proposed. Other researchers have explored parametric surrogates or hybrid models to improve scalability and adaptivity.

The choice of input parameterisation has a large influence on BO performance. Transformations such as log-scaling, normalization, or learned input warping (e.g., the Warped GP approach) can make the function easier to model. Structured kernels or embeddings can also encode domain knowledge or correlations between inputs, improving sample efficiency.

The acquisition function determines where to evaluate the objective next. It embeds the surrogate model and assigns each candidate input a scalar utility reflecting both its uncertainty and its predicted value. Common acquisition functions include Expected Improvement (EI), Upper Confidence Bound (UCB), and Probability of Improvement (PI). Variants such as Entropy Search, Predictive Entropy Search, and Knowledge Gradient explicitly account for information gain.

Given the acquisition landscape, the next query function selects the actual input(s) to evaluate, often by maximizing the acquisition function. Extensions to batch or multi-step lookahead settings select multiple or future evaluations jointly, considering correlations and proximity between proposed points. In batch BO, researchers have proposed strategies to encourage diversity among selected points.

Bayesian Optimisation has been widely used in hyperparameter tuning of machine learning models, materials and drug discovery, engineering design, and experimental control—anywhere function evaluations are costly or noisy. Its success depends on careful choices of surrogate model, acquisition function, input representation, and initial sampling strategy, all of which shape the efficiency and accuracy of the optimisation process.

Below, we provide a description of the environments (objective functions) that you can use to develop an algorithm to maximise black-box objectives. Even though you might know the points that maximise the training objective functions, be aware that any code you develop will be applied to other BO objective functions and that you will be assessed on your performance on these held-out tasks - hence, ensure that the algorithm is generaliseable.
